{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4a65deb-102e-4ad2-92f2-3ff9d340a96b",
   "metadata": {},
   "source": [
    "# Splątane sieci neuronowe CNN – architektura Xception \n",
    "---\n",
    "autor: mgr inż. Grzegorz Kossakowski"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de60196-61c7-4979-8274-35c7548943c0",
   "metadata": {},
   "source": [
    "## 1. Opis architektury"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b810301-6c7e-452c-93ad-2d2a0613cdb8",
   "metadata": {},
   "source": [
    "Xception [1][2][3] jest architekturą splątanych sieci neuronowych CNN. Pełna nazwa architektury to Extreme Inception. Powstał w 2017 roku jako ewolucja architektury Inception i został stworzony przez firmę Google. Architektura Xception okazała się bardziej wydajna od VGG-16, ResNet i Inception v3. Głęboko rozdzielny sploty są uznawane za znacznie bardziej wydajne pod względem czasu obliczeń.\n",
    "Znakiem firmowym Xception jest wykorzystanie głęboko rozdzielnych splotów. Jest to bardzo wydajna architektura oparta na dwóch krokach:\n",
    "- Głęboko rozdzielny splot\n",
    "- Splot punktowy\n",
    "\n",
    "\n",
    "Ogólna architektura składa się z trzech przepływów:\n",
    "- Przepływ wejściowy\n",
    "- Przepływ środkową, w której proces jest powtarzany osiem razy\n",
    "- Przepływ wyjściowy. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a75435b-d66d-44e6-a2fa-5ecc48e2b38c",
   "metadata": {},
   "source": [
    "## 2. Pobranie potrzebnych bibliotek\n",
    "Kolejnym krokiem jest wczytanie wszystkich potrzebnych bibliotek, dzięki którym będzie możliwe wykorzystanie ich w procesie klasyfikacji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a82fd330-0d74-4c15-8f26-3da61c332ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_ENABLE_ONEDNN_OPTS=0\n",
    "from astropy.io import fits\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "from keras import Sequential\n",
    "from tests.test_layers import Dense, Flatten\n",
    "from keras.applications import Xception\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00adab72-d8c2-4a5c-92c7-7f2d54de5cb9",
   "metadata": {},
   "source": [
    "## 3. Pobranie danych z pliku fits\n",
    "Dlatego że wcześniej podzieliliśmy dane na odpowiednie części, teraz pobieramy dwa zbiory. Pierwszy z nich to zbiór, na którym będziemy uczyć nasz model. Drugi to zbiór walidacyjny."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "843b6bd8-8577-4d40-8d3d-bdee4e18c264",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdu_train = fits.open('Data/train.fits')\n",
    "hdu_valid = fits.open('Data/valid.fits')\n",
    "x_train = hdu_train[0].data\n",
    "y_train = hdu_train[1].data\n",
    "x_valid = hdu_valid[0].data\n",
    "y_valid = hdu_valid[1].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9690d858-350e-4064-84f7-911ebab4f971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11350, 256, 256, 3), (2838, 256, 256, 3), numpy.ndarray)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_valid.shape, type(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe8f6a5-f34e-4868-9f24-83de36f2dc70",
   "metadata": {},
   "source": [
    "## 4. Ustawienie sposobu nauki\n",
    "Modele, które używany są już wstępnie wyuczone, dlatego chciałem sprawdzić, jak dany model będzie się zachowywał w dwóch przypadkach. Pierwszy przypadek gdy wartość fullStudy zostanie ustawiona na false wtedy model będzie wykorzystywał wcześniej nauczony model i na ostatnich warstwach będzie douczał tylko danymi astronomicznymi. Gdy ustawimy wartość na true, model od początku będzie, wykonał naukę architektury. Wcześniejsza nauka nie będzie brana pod uwagę. Pozwoli to ocenić, który sposób jest bardziej efektywny."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff4bce2d-1998-4ba5-bfea-3e711377cb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fullStudy = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf6a960-35f6-46d1-bb0a-c5a67fa0d668",
   "metadata": {},
   "source": [
    "## 5. Pobranie danych \n",
    "W tym kroku pobieramy dane, a następnie przygotowujemy je do klasyfikacji. Modele głębokiej sieci neuronowej [4] wymaga danych z zakresu 0..1, dlatego wszystkie wartości w danych są dzielone przez 255. Powodem takiego zachowania jest fakt, że dane obrazów są przechowywane w zakresie liczb 0..255. Dzielenie przez 255 powoduje, że dane zostaną zapisane w zakresie od 0..1, zgodnie z wymaganiami modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13190918-6978-4357-9e7c-b92b7c2fd775",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduceLR = ReduceLROnPlateau(monitor='accuracy', factor=.001, patience=1, min_delta=0.01, mode=\"auto\")\n",
    "x_train = x_train / 255.0\n",
    "x_valid = x_valid / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd9eb4f-630c-47a8-9581-ae56dfce14dc",
   "metadata": {},
   "source": [
    "## 6. Budowa modelu.\n",
    "Model został stworzony w 2017 roku. Jest to model, który powstał na podstawie modelu Inception. Po wykonaniu warstw splątanych następuje przejście przez warstwę flatten. Zadaniem tej warstwy jest spłaszczenie obrazu z wymiarów, które zostały po przejściu przez warstwy splątane na pojedynczy ciąg. Ostatnią warstwą jest gęsto połączona warstwa wyjściowa. W naszym modelu klasyfikacja odbywa się dla 10 kategorii dlatego właśnie taka."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fbf1f63-8a28-4a35-a980-dc3b8b5960c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " xception (Functional)       (None, 8, 8, 2048)        20861480  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 131072)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                1310730   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22172210 (84.58 MB)\n",
      "Trainable params: 1310730 (5.00 MB)\n",
      "Non-trainable params: 20861480 (79.58 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = Xception(weights='imagenet', include_top=False, input_shape=(256, 256,3))\n",
    "base_model.trainable = fullStudy\n",
    "model_optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer=model_optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7559b8dc-5bd2-4c64-8269-dd11088753ca",
   "metadata": {},
   "source": [
    "## 7. Uczenie\n",
    "W tym momencie model zaczyna proces uczenia. Czyli otrzymuje dwa zbiory danych i etykiet. Pierwszy z nich to dane, na podstawie których model się uczy. Drugi mniejszy zbiór jest zbiorem walidacyjnym, który pozwala na sprawdzenie postępów w nauce, na danych, których model jeszcze nie widział. Pozwala to ocenić postępy w nauce już w czasie uczenia. Kolejny zbiór danych zostanie wykorzystany na końcu celem ostatecznego sprawdzenia poprawności działania modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cd86063-8618-4297-bfbd-04b43cdbab62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "355/355 [==============================] - 450s 1s/step - loss: 3.6741 - accuracy: 0.4576 - val_loss: 2.9911 - val_accuracy: 0.4961 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "355/355 [==============================] - 418s 1s/step - loss: 2.2864 - accuracy: 0.5997 - val_loss: 2.7150 - val_accuracy: 0.5536 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "355/355 [==============================] - 416s 1s/step - loss: 1.5939 - accuracy: 0.6880 - val_loss: 4.1401 - val_accuracy: 0.4824 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "355/355 [==============================] - 415s 1s/step - loss: 1.3554 - accuracy: 0.7256 - val_loss: 3.2788 - val_accuracy: 0.5395 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "355/355 [==============================] - 414s 1s/step - loss: 1.0843 - accuracy: 0.7733 - val_loss: 3.2492 - val_accuracy: 0.5937 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "355/355 [==============================] - 414s 1s/step - loss: 0.9025 - accuracy: 0.8012 - val_loss: 3.5235 - val_accuracy: 0.5550 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "355/355 [==============================] - 414s 1s/step - loss: 0.7635 - accuracy: 0.8278 - val_loss: 3.4815 - val_accuracy: 0.5620 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "355/355 [==============================] - 414s 1s/step - loss: 0.6605 - accuracy: 0.8528 - val_loss: 4.1052 - val_accuracy: 0.5437 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "355/355 [==============================] - 415s 1s/step - loss: 0.5163 - accuracy: 0.8804 - val_loss: 3.7577 - val_accuracy: 0.5888 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "355/355 [==============================] - 417s 1s/step - loss: 0.5334 - accuracy: 0.8802 - val_loss: 3.7047 - val_accuracy: 0.5909 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=10, callbacks=[reduceLR],validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10682377-5fd3-41bb-86cf-ecd5122023ca",
   "metadata": {},
   "source": [
    "## 8. Zapis architektury\n",
    "Jednak my nie będziemy testować od razu naszego modelu. Do tego celu przygotujemy oddzielny notebook. Dlatego, aby nie utracić naszej pracy, zapiszemy nas wyuczony model do pliku."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08dcdc15-eaf9-4d43-8ba3-07f7622d96d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if fullStudy == True:\n",
    "    model.save('Models/Xception_full.keras')\n",
    "else:\n",
    "    model.save('Models/Xception.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c425c8-409e-4d8f-ab45-4b2d14e94899",
   "metadata": {},
   "source": [
    "## 9. Zapis otrzymanych danych podczas nauki\n",
    "Po zakończeniu uczenia zapisujemy dane, które otrzymaliśmy podczas uczenie do pliku CSV. Pozwoli nam to później przeanalizować dane w późniejszym czasie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94aa1164-7182-4eda-a612-62f9c3fcac6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "historyModelLearning = pd.DataFrame()\n",
    "historyModelLearning['loss'] = history.history['loss']\n",
    "historyModelLearning['accuracy'] = history.history['accuracy']\n",
    "historyModelLearning['val_loss'] = history.history['val_loss']\n",
    "historyModelLearning['val_accuracy'] = history.history['val_accuracy']\n",
    "if fullStudy == True:\n",
    "    historyModelLearning.to_csv('ResultLearning/Xception_full.csv', index=True)\n",
    "else:\n",
    "    historyModelLearning.to_csv('ResultLearning/Xception.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e63262-e19c-48a1-a8a9-a471fe379205",
   "metadata": {},
   "source": [
    "## Literatura\n",
    "1. https://maelfabien.github.io/deeplearning/xception/#\n",
    "2. https://towardsdatascience.com/review-xception-with-depthwise-separable-convolution-better-than-inception-v3-image-dc967dd42568\n",
    "3. https://medium.com/@saba99/xception-cd1adc84290f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b6d647-b5be-4221-9044-81643f9b6e1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
