{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4a65deb-102e-4ad2-92f2-3ff9d340a96b",
   "metadata": {},
   "source": [
    "# Splątane sieci neuronowe CNN – architektura LeNet-5\n",
    "---\n",
    "autor: mgr inż. Grzegorz Kossakowski"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de60196-61c7-4979-8274-35c7548943c0",
   "metadata": {},
   "source": [
    "## 1. Opis architektury\n",
    "LeNet-5 jest to pierwsza sieć splątana [1] jaka powstała. Została zbudowana w 1999 przez Yann LeCun, Leon Bottou, Yoshua Bengio i Patricka Haffnera. Celem było rozpoznawanie numerów kodów pocztowych napisanych przez ludzi na listach. Dzięki temu, że projekt odniósł sukces, znaleziono praktyczne zastosowanie dla tej technologii. Zawiera ona dwie warstwy splatane oraz sieć neuronową. W tej sieci wykorzystuje warstwę flaten do spłaszczenia obrazów po przejściu przez warstwy splatane oraz dwie warstwy ukryte gęste. Ostatnia warstwa, jest warstwa wyjściowa, która zawiera 10 neuronów, czyli dokładnie tyle ile jest kategorii w naszych danych."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a75435b-d66d-44e6-a2fa-5ecc48e2b38c",
   "metadata": {},
   "source": [
    "## 2. Pobranie potrzebnych bibliotek\n",
    "Kolejnym krokiem jest wczytanie wszystkich potrzebnych bibliotek, dzięki którym będzie możliwe wykorzystanie ich w procesie klasyfikacji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a82fd330-0d74-4c15-8f26-3da61c332ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_ENABLE_ONEDNN_OPTS=0\n",
    "from astropy.io import fits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, AveragePooling2D, Flatten, Dense\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "from astroNN.datasets import galaxy10sdss\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "import pathlib\n",
    "import datetime\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00adab72-d8c2-4a5c-92c7-7f2d54de5cb9",
   "metadata": {},
   "source": [
    "## 3. Pobranie danych z pliku fits\n",
    "Dlatego że wcześniej podzieliliśmy dane na odpowiednie części, teraz pobieramy dwa zbiory. Pierwszy z nich to zbiór, na którym będziemy uczyć nasz model. Drugi to zbiór walidacyjny."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "843b6bd8-8577-4d40-8d3d-bdee4e18c264",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdu_train = fits.open('Data/train.fits')\n",
    "hdu_valid = fits.open('Data/valid.fits')\n",
    "hdu_test = fits.open('Data/test.fits')\n",
    "x_train = hdu_train[0].data\n",
    "y_train = hdu_train[1].data\n",
    "x_valid = hdu_valid[0].data\n",
    "y_valid = hdu_valid[1].data\n",
    "x_test = hdu_test[0].data\n",
    "y_test = hdu_test[1].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9690d858-350e-4064-84f7-911ebab4f971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11350, 256, 256, 3), (2838, 256, 256, 3), (3548, 256, 256, 3), numpy.ndarray)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_valid.shape, x_test.shape, type(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf6a960-35f6-46d1-bb0a-c5a67fa0d668",
   "metadata": {},
   "source": [
    "## 4. Pobranie danych \n",
    "W tym kroku pobieramy dane, a następnie przygotowujemy je do klasyfikacji. Modele głębokiej sieci neuronowej [4] wymaga danych z zakresu 0..1, dlatego wszystkie wartości w danych są dzielone przez 255. Powodem takiego zachowania jest fakt, że dane obrazów są przechowywane w zakresie liczb 0..255. Dzielenie przez 255 powoduje, że dane zostaną zapisane w zakresie od 0..1, zgodnie z wymaganiami modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13190918-6978-4357-9e7c-b92b7c2fd775",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduceLR = ReduceLROnPlateau(monitor='accuracy', factor=.001, patience=1, min_delta=0.01, mode=\"auto\")\n",
    "x_train = x_train / 255.0\n",
    "x_valid = x_valid / 255.0\n",
    "x_test = x_test/ 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd9eb4f-630c-47a8-9581-ae56dfce14dc",
   "metadata": {},
   "source": [
    "## 5. Budowa modelu.\n",
    "Model można podzielić na dwie podstawowe części. Pierwsza część to warstwy splątane. Naprzemiennie są układane warstwy Conv2D, AveragePooling2D. Kolejność ułożenia warstw jest zgodna z LeNet5. Kolejną część to już model głębokiego uczenia. Pierwszą warstwo jest flatten. Zadaniem tej warstwy jest spłaszczenie obrazu po przejściu warstw splątanych do pojedynczego ciągu. Kolejne warstwy to warstwy ukryte z aktywatorem tanh. Czyli funkcja tangensa hiperbolicznego. Jest bardzo podobna do sigmoidu, ale rozciągnieta w zakresie od -1 do 1. Ostatnią warstwą jest gęsto połączona warstwa wyjściowa. W naszym modelu klasyfikacja odbywa się dla 10 kategorii dlatego właśnie zawiera tyle neuronów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fbf1f63-8a28-4a35-a980-dc3b8b5960c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 252, 252, 6)       456       \n",
      "                                                                 \n",
      " average_pooling2d (Average  (None, 126, 126, 6)       0         \n",
      " Pooling2D)                                                      \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 122, 122, 16)      2416      \n",
      "                                                                 \n",
      " average_pooling2d_1 (Avera  (None, 61, 61, 16)        0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 59536)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 120)               7144440   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 84)                10164     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                850       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7158326 (27.31 MB)\n",
      "Trainable params: 7158326 (27.31 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters=6, kernel_size=(5,5), strides=(1,1), activation='tanh', input_shape=(256,256,3)))\n",
    "model.add(AveragePooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Conv2D(filters=16, kernel_size=(5,5), strides=(1,1), activation='tanh'))\n",
    "model.add(AveragePooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=120, activation='tanh'))\n",
    "model.add(Dense(units=84, activation='tanh'))\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "model_optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=model_optimizer, loss='sparse_categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7559b8dc-5bd2-4c64-8269-dd11088753ca",
   "metadata": {},
   "source": [
    "## 6. Uczenie\n",
    "W tym momencie model zaczyna proces uczenia. Czyli otrzymuje dwa zbiory danych i etykiet. Pierwszy z nich to dane, na podstawie których model się uczy. Drugi mniejszy zbiór jest zbiorem walidacyjnym, który pozwala na sprawdzenie postępów w nauce, na danych, których model jeszcze nie widział. Pozwala to ocenić postępy w nauce już w czasie uczenia. Kolejny zbiór danych zostanie wykorzystany na końcu celem ostatecznego sprawdzenia poprawności działania modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cd86063-8618-4297-bfbd-04b43cdbab62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "355/355 [==============================] - 42s 115ms/step - loss: 2.2537 - accuracy: 0.1402 - val_loss: 2.2709 - val_accuracy: 0.1388 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "355/355 [==============================] - 33s 94ms/step - loss: 2.2353 - accuracy: 0.1434 - val_loss: 2.2404 - val_accuracy: 0.1508 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "355/355 [==============================] - 33s 93ms/step - loss: 2.2432 - accuracy: 0.1480 - val_loss: 2.2374 - val_accuracy: 0.1508 - lr: 1.0000e-06\n",
      "Epoch 4/10\n",
      "355/355 [==============================] - 33s 93ms/step - loss: 2.2415 - accuracy: 0.1480 - val_loss: 2.2374 - val_accuracy: 0.1508 - lr: 1.0000e-09\n",
      "Epoch 5/10\n",
      "355/355 [==============================] - 33s 94ms/step - loss: 2.2415 - accuracy: 0.1480 - val_loss: 2.2374 - val_accuracy: 0.1508 - lr: 1.0000e-12\n",
      "Epoch 6/10\n",
      "355/355 [==============================] - 34s 95ms/step - loss: 2.2415 - accuracy: 0.1480 - val_loss: 2.2374 - val_accuracy: 0.1508 - lr: 1.0000e-15\n",
      "Epoch 7/10\n",
      "355/355 [==============================] - 34s 95ms/step - loss: 2.2415 - accuracy: 0.1480 - val_loss: 2.2374 - val_accuracy: 0.1508 - lr: 1.0000e-18\n",
      "Epoch 8/10\n",
      "355/355 [==============================] - 33s 94ms/step - loss: 2.2415 - accuracy: 0.1480 - val_loss: 2.2374 - val_accuracy: 0.1508 - lr: 1.0000e-21\n",
      "Epoch 9/10\n",
      "355/355 [==============================] - 34s 95ms/step - loss: 2.2415 - accuracy: 0.1480 - val_loss: 2.2374 - val_accuracy: 0.1508 - lr: 1.0000e-24\n",
      "Epoch 10/10\n",
      "355/355 [==============================] - 33s 94ms/step - loss: 2.2415 - accuracy: 0.1480 - val_loss: 2.2374 - val_accuracy: 0.1508 - lr: 1.0000e-27\n",
      "Potrzebny czas do wykonania operacji to:  6  minut\n"
     ]
    }
   ],
   "source": [
    "now = datetime.datetime.now()\n",
    "history = model.fit(x_train, y_train, epochs=10, callbacks=[reduceLR],validation_data=(x_valid, y_valid))\n",
    "time = datetime.datetime.now()-now\n",
    "print(\"Potrzebny czas do wykonania operacji to: \",int(time.seconds/60),\" minut\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10682377-5fd3-41bb-86cf-ecd5122023ca",
   "metadata": {},
   "source": [
    "## 7. Zapis architektury"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08dcdc15-eaf9-4d43-8ba3-07f7622d96d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Models/LeNet5_full.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c425c8-409e-4d8f-ab45-4b2d14e94899",
   "metadata": {},
   "source": [
    "## 8. Zapis otrzymanych danych podczas nauki\n",
    "Po zakończeniu uczenia zapisujemy dane, które otrzymaliśmy podczas uczenie do pliku CSV. Pozwoli nam to później przeanalizować dane w późniejszym czasie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94aa1164-7182-4eda-a612-62f9c3fcac6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "historyModelLearning = pd.DataFrame()\n",
    "historyModelLearning['loss'] = history.history['loss']\n",
    "historyModelLearning['accuracy'] = history.history['accuracy']\n",
    "historyModelLearning['val_loss'] = history.history['val_loss']\n",
    "historyModelLearning['val_accuracy'] = history.history['val_accuracy']\n",
    "historyModelLearning.to_csv('ResultLearning/LeNet5_full.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e037bd0e-756a-4c42-8434-27cd744e13bd",
   "metadata": {},
   "source": [
    "## 9. Sprawdzenie uzyskanych wyników\n",
    "Celem tego elementu jest wstępne sprawdzenie uzyskanych wyników. Pozwoli to na porównanie wyników z predykcją w zapisanym modelu. Dzięki temu uzyskamy informację czy otrzymane wyniku różnią się od siebie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a2850cd-c648-4f91-a454-5b1c4240ef8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111/111 [==============================] - 3s 24ms/step\n",
      "Otrzymany wynik to:  15.135287485907552  %\n"
     ]
    }
   ],
   "source": [
    "predict = model.predict(x_test).argmax(axis=1)\n",
    "print(\"Otrzymany wynik to: \",(accuracy_score(y_test, predict)*100),\" %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e63262-e19c-48a1-a8a9-a471fe379205",
   "metadata": {},
   "source": [
    "## Literatura\n",
    "1. Bartosz Michalski, Małgorzata Plechawska-Wójcik, Porównanie modeli LeNet-5, AlexNet i GoogLeNet w rozpoznawaniu pisma ręcznego, 2022\n",
    "2. https://builtin.com/machine-learning/relu-activation-function\n",
    "3. https://datascience.eu/pl/uczenie-maszynowe/relu-funkcja-aktywujaca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b6d647-b5be-4221-9044-81643f9b6e1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
