{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4a65deb-102e-4ad2-92f2-3ff9d340a96b",
   "metadata": {},
   "source": [
    "# Splątane sieci neuronowe CNN – architektura MobileNet\n",
    "---\n",
    "Autor: mgr inż. Grzegorz Kossakowski"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de60196-61c7-4979-8274-35c7548943c0",
   "metadata": {},
   "source": [
    "## 1. Opis architektury\n",
    "MobileNet [1] jest to architektura, stworzoną przez firmę Google do wykorzystania w urządzeniach mobilnych.\n",
    "W porównaniu do innych CNN celem było, ograniczone liczby parametrów do nauczenia, dzięki temu architektura nadaje się do wykorzystania na dużo słabszych urządzeniach. Osiągnięto to przez wykorzystanie splotu rozdzielonego wgłębnie. Taki splot składa się z dwóch operacji splotu: głęboki i punktowy. Pierwsza wersja została zaprezentowana w 2017."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a75435b-d66d-44e6-a2fa-5ecc48e2b38c",
   "metadata": {},
   "source": [
    "## 2. Pobranie potrzebnych bibliotek\n",
    "Kolejnym krokiem jest wczytanie wszystkich potrzebnych bibliotek, dzięki którym będzie możliwe wykorzystanie ich w procesie klasyfikacji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a82fd330-0d74-4c15-8f26-3da61c332ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_ENABLE_ONEDNN_OPTS=0\n",
    "from astropy.io import fits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "from keras import Sequential\n",
    "from tests.test_layers import Dense, Flatten\n",
    "from keras.applications import MobileNetV3Large\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00adab72-d8c2-4a5c-92c7-7f2d54de5cb9",
   "metadata": {},
   "source": [
    "## 3. Pobranie danych z pliku fits\n",
    "Dlatego że wcześniej podzieliliśmy dane na odpowiednie części, teraz pobieramy dwa zbiory. Pierwszy z nich to zbiór, na którym będziemy uczyć nasz model. Drugi to zbiór walidacyjny."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "843b6bd8-8577-4d40-8d3d-bdee4e18c264",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdu_train = fits.open('Data/train.fits')\n",
    "hdu_valid = fits.open('Data/valid.fits')\n",
    "x_train = hdu_train[0].data\n",
    "y_train = hdu_train[1].data\n",
    "x_valid = hdu_valid[0].data\n",
    "y_valid = hdu_valid[1].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9690d858-350e-4064-84f7-911ebab4f971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11350, 256, 256, 3), (2838, 256, 256, 3), numpy.ndarray)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_valid.shape, type(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee00baa-022d-494f-8208-cca688bb410d",
   "metadata": {},
   "source": [
    "## 4. Ustawienie sposobu nauki\n",
    "Modele, które używany są już wstępnie wyuczone, dlatego chciałem sprawdzić, jak dany model będzie się zachowywał w dwóch przypadkach. Pierwszy przypadek gdy wartość fullStudy zostanie ustawiona na false wtedy model będzie wykorzystywał wcześniej nauczony model i na ostatnich warstwach będzie douczał tylko danymi astronomicznymi. Gdy ustawimy wartość na true, model od początku będzie, wykonał naukę architektury. Wcześniejsza nauka nie będzie brana pod uwagę. Pozwoli to ocenić, który sposób jest bardziej efektywny."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9e0352a-578f-4a10-888d-1775758b174b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fullStudy = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf6a960-35f6-46d1-bb0a-c5a67fa0d668",
   "metadata": {},
   "source": [
    "## 5. Pobranie danych \n",
    "W tym kroku pobieramy dane, a następnie przygotowujemy je do klasyfikacji. Modele głębokiej sieci neuronowej [4] wymaga danych z zakresu 0..1, dlatego wszystkie wartości w danych są dzielone przez 255. Powodem takiego zachowania jest fakt, że dane obrazów są przechowywane w zakresie liczb 0..255. Dzielenie przez 255 powoduje, że dane zostaną zapisane w zakresie od 0..1, zgodnie z wymaganiami modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13190918-6978-4357-9e7c-b92b7c2fd775",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduceLR = ReduceLROnPlateau(monitor='accuracy', factor=.001, patience=1, min_delta=0.01, mode=\"auto\")\n",
    "x_train = x_train / 255.0\n",
    "x_valid = x_valid / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd9eb4f-630c-47a8-9581-ae56dfce14dc",
   "metadata": {},
   "source": [
    "## 6. Budowa modelu.\n",
    "Model w tym przypadku to MobileNetV3Large. Po warstwach splątanych jest warstwa flatten. Zadaniem tej warstwy jest spłaszczenie obrazu z wymiarów otrzymanych po przejściu warstw splątanych do pojedynczego ciągu. Ostatnią warstwą jest gęsto połączona warstwa wyjściowa. W naszym modelu klasyfikacja odbywa się dla 10 kategorii, dlatego ta warstwa ma 10 neuronów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fbf1f63-8a28-4a35-a980-dc3b8b5960c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not 224. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " MobilenetV3large (Function  (None, 1000)              5507432   \n",
      " al)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 1000)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                10010     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5517442 (21.05 MB)\n",
      "Trainable params: 10010 (39.10 KB)\n",
      "Non-trainable params: 5507432 (21.01 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = MobileNetV3Large(weights='imagenet', input_shape=(256, 256,3))\n",
    "base_model.trainable = fullStudy\n",
    "model_optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer=model_optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7559b8dc-5bd2-4c64-8269-dd11088753ca",
   "metadata": {},
   "source": [
    "## 7. Uczenie\n",
    "W tym momencie model zaczyna proces uczenia. Czyli otrzymuje dwa zbiory danych i etykiet. Pierwszy z nich to dane, na podstawie których model się uczy. Drugi mniejszy zbiór jest zbiorem walidacyjnym, który pozwala na sprawdzenie postępów w nauce, na danych, których model jeszcze nie widział. Pozwala to ocenić postępy w nauce już w czasie uczenia. Kolejny zbiór danych zostanie wykorzystany na końcu celem ostatecznego sprawdzenia poprawności działania modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cd86063-8618-4297-bfbd-04b43cdbab62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "355/355 [==============================] - 105s 285ms/step - loss: 2.2628 - accuracy: 0.1431 - val_loss: 2.2392 - val_accuracy: 0.1508 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "355/355 [==============================] - 86s 242ms/step - loss: 2.2322 - accuracy: 0.1453 - val_loss: 2.2261 - val_accuracy: 0.1388 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "355/355 [==============================] - 86s 243ms/step - loss: 2.2267 - accuracy: 0.1491 - val_loss: 2.2261 - val_accuracy: 0.1388 - lr: 1.0000e-06\n",
      "Epoch 4/10\n",
      "355/355 [==============================] - 86s 243ms/step - loss: 2.2267 - accuracy: 0.1491 - val_loss: 2.2261 - val_accuracy: 0.1388 - lr: 1.0000e-09\n",
      "Epoch 5/10\n",
      "355/355 [==============================] - 86s 243ms/step - loss: 2.2267 - accuracy: 0.1491 - val_loss: 2.2261 - val_accuracy: 0.1388 - lr: 1.0000e-12\n",
      "Epoch 6/10\n",
      "355/355 [==============================] - 86s 243ms/step - loss: 2.2268 - accuracy: 0.1491 - val_loss: 2.2261 - val_accuracy: 0.1388 - lr: 1.0000e-15\n",
      "Epoch 7/10\n",
      "355/355 [==============================] - 86s 243ms/step - loss: 2.2268 - accuracy: 0.1491 - val_loss: 2.2261 - val_accuracy: 0.1388 - lr: 1.0000e-18\n",
      "Epoch 8/10\n",
      "355/355 [==============================] - 86s 243ms/step - loss: 2.2267 - accuracy: 0.1491 - val_loss: 2.2261 - val_accuracy: 0.1388 - lr: 1.0000e-21\n",
      "Epoch 9/10\n",
      "355/355 [==============================] - 86s 244ms/step - loss: 2.2267 - accuracy: 0.1491 - val_loss: 2.2261 - val_accuracy: 0.1388 - lr: 1.0000e-24\n",
      "Epoch 10/10\n",
      "355/355 [==============================] - 87s 244ms/step - loss: 2.2267 - accuracy: 0.1491 - val_loss: 2.2261 - val_accuracy: 0.1388 - lr: 1.0000e-27\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=10, callbacks=[reduceLR],validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10682377-5fd3-41bb-86cf-ecd5122023ca",
   "metadata": {},
   "source": [
    "## 8. Zapis architektury"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08dcdc15-eaf9-4d43-8ba3-07f7622d96d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if fullStudy == True:\n",
    "    model.save('Models/MobileNet_full.keras')\n",
    "else:\n",
    "    model.save('Models/MobileNet.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c425c8-409e-4d8f-ab45-4b2d14e94899",
   "metadata": {},
   "source": [
    "## 9. Zapis otrzymanych danych podczas nauki\n",
    "Po zakończeniu uczenia zapisujemy dane, które otrzymaliśmy podczas uczenie do pliku CSV. Pozwoli nam to później przeanalizować dane w późniejszym czasie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94aa1164-7182-4eda-a612-62f9c3fcac6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "historyModelLearning = pd.DataFrame()\n",
    "historyModelLearning['loss'] = history.history['loss']\n",
    "historyModelLearning['accuracy'] = history.history['accuracy']\n",
    "historyModelLearning['val_loss'] = history.history['val_loss']\n",
    "historyModelLearning['val_accuracy'] = history.history['val_accuracy']\n",
    "if fullStudy == True:\n",
    "    historyModelLearning.to_csv('ResultLearning/MobileNet_full.csv', index=True)\n",
    "else:\n",
    "    historyModelLearning.to_csv('ResultLearning/MobileNet.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e63262-e19c-48a1-a8a9-a471fe379205",
   "metadata": {},
   "source": [
    "## Literatura\n",
    "1. https://towardsdatascience.com/everything-you-need-to-know-about-mobilenetv3-and-its-comparison-with-previous-versions-a5d5e5a6eeaa dostęp 2024-01-04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b485eeb-a669-4d9b-93fc-ce01ee6147e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
