{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7e562c9-2483-4bfe-879e-cafbade4730f",
   "metadata": {},
   "source": [
    "# Głębokie sieci neuronowe DNN\n",
    "---\n",
    "***Autor: mgr inż. Grzegorz Kossakowski***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1494049d-ed51-48d8-aac9-d6794e564aca",
   "metadata": {},
   "source": [
    "## 1. Opis architektury\n",
    "Głęboka sieć neuronowa [1], jest to prosta sieć bez żadnej warstwy splatanej. Składa się z warstwy wejściowej flaten, której podstawowym zadaniem jest wypłaszczenie przekazanego obrazu. Kolejna warstwa to jedna warstwa ukryta oraz warstwy wyjściowej. Celem tego notebook jest uzyskanie danych do porównania, jak mocno poprawą się wyniki po zastosowaniu warstw splątanych."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a55c447-b3ac-4b93-8586-8b6650e6d1b1",
   "metadata": {},
   "source": [
    "## 2. Pobranie potrzebnych bibliotek\n",
    "Kolejnym kroku wczytujemy wszystkie potrzebne biblioteki, dzięki którym będzie możliwe wykorzystanie ich w procesie uczenia i zapisywania modelu oraz danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "655bb29d-e4c3-4e3e-89ea-84eb9e270b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_ENABLE_ONEDNN_OPTS=0\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "from astropy.io import fits\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b769bf05-7cea-46ed-b849-5f189b058172",
   "metadata": {},
   "source": [
    "## 3. Pobranie danych z pliku fits\n",
    "Dlatego, że wcześniej podzieliliśmy dane na odpowiednie części, teraz pobieramy dwa zbiory. Pierwszy z nich to zbiór uczący, na którym będziemy uczyć nasz model. Drugi to zbiór walidacyjny, na tym zbiorze będziemy sprawdzać, jak uczy się nasz model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "784f05ff-84e5-43b9-9f4f-c9a7d6b467f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdu_train = fits.open('Data/train.fits')\n",
    "hdu_valid = fits.open('Data/valid.fits')\n",
    "hdu_test = fits.open('Data/test.fits')\n",
    "x_train = hdu_train[0].data\n",
    "y_train = hdu_train[1].data\n",
    "x_valid = hdu_valid[0].data\n",
    "y_valid = hdu_valid[1].data\n",
    "x_test = hdu_test[0].data\n",
    "y_test = hdu_test[1].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fca5eb1-bf06-4f9d-b384-745b203dcd80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11350, 256, 256, 3), (2838, 256, 256, 3), (3548, 256, 256, 3), numpy.ndarray)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_valid.shape, x_test.shape, type(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece9343b-a9a5-4ce8-ae02-77eefe947a5b",
   "metadata": {},
   "source": [
    "## 4. Przygotowanie danych \n",
    "Modele głębokiej sieci neuronowej [2] wymaga danych z zakresu 0..1, dlatego wszystkie wartości w danych są dzielone przez 255. Powodem takiego zachowania jest fakt, że dane obrazów są przechowywane w zakresie liczb 0..255. Dzielenie przez 255 powoduje, że dane zostaną zapisane w zakresie od 0..1, zgodnie z wymaganiami modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a279414-a011-46c0-863c-1e44f071cc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduceLR = ReduceLROnPlateau(monitor='accuracy', factor=.001, patience=1, min_delta=0.01, mode=\"auto\")\n",
    "x_train = x_train / 255.0\n",
    "x_valid = x_valid / 255.0\n",
    "x_test = x_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30806b9-629a-4ae5-bc14-1fd9473a385d",
   "metadata": {},
   "source": [
    "## 5. Budowa modelu.\n",
    "Budowany model jest modelem warstwowym i jako pierwsza warstwa jest to warstwa flatten. Zadaniem tej warstwy jest spłaszczenie obrazu z wymiarów 256 * 256 na pojedynczy ciąg, jest to warstwa wejściowa. Kolejną warstwą jest warstwa ukryta z aktywatorem RELU. Aktywator ten powoduje, że każdy otrzymany wynik ujemy, zostaje zamieniony na zero [3][4]. Pozwala to na przełamanie liniowości procesu. Ostatnią warstwą jest gęsto połączona warstwa wyjściowa. W naszym modelu klasyfikacja odbywa się dla 10 kategorii, dlatego zawiera dokładnie 10 neuronów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c19807a4-dfbd-49b3-8107-288c29aa3e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 196608)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               25165952  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25167242 (96.01 MB)\n",
      "Trainable params: 25167242 (96.01 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(256,256,3)))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model_optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "model.compile(optimizer=model_optimizer, loss='sparse_categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0047b432-dddd-4c0d-b255-fa152b06db7f",
   "metadata": {},
   "source": [
    "## 6. Uczenie\n",
    "W tym momencie model zaczyna proces uczenia. Czyli otrzymuje dwa zbiory danych. Pierwszy z nich to dane, na podstawie których model się uczy, czyli zbiór uczący. Drugi mniejszy zbiór jest zbiorem walidacyjnym, który pozwala na sprawdzenie postępów w nauce, na danych, których model jeszcze nie widział. Dzięki temu możemy ocenić postępy w nauce już w czasie uczenia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "280c9d9d-1fb3-4c0a-8f95-d0fdabe2628e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "355/355 [==============================] - 48s 132ms/step - loss: 3.9176 - accuracy: 0.1922 - val_loss: 2.2946 - val_accuracy: 0.1508 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "355/355 [==============================] - 38s 106ms/step - loss: 2.2770 - accuracy: 0.1468 - val_loss: 2.2581 - val_accuracy: 0.1508 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "355/355 [==============================] - 38s 106ms/step - loss: 2.2583 - accuracy: 0.1480 - val_loss: 2.2580 - val_accuracy: 0.1508 - lr: 1.0000e-06\n",
      "Epoch 4/10\n",
      "355/355 [==============================] - 38s 106ms/step - loss: 2.2582 - accuracy: 0.1480 - val_loss: 2.2580 - val_accuracy: 0.1508 - lr: 1.0000e-09\n",
      "Epoch 5/10\n",
      "355/355 [==============================] - 38s 107ms/step - loss: 2.2582 - accuracy: 0.1480 - val_loss: 2.2580 - val_accuracy: 0.1508 - lr: 1.0000e-12\n",
      "Epoch 6/10\n",
      "355/355 [==============================] - 38s 106ms/step - loss: 2.2582 - accuracy: 0.1480 - val_loss: 2.2580 - val_accuracy: 0.1508 - lr: 1.0000e-15\n",
      "Epoch 7/10\n",
      "355/355 [==============================] - 38s 106ms/step - loss: 2.2582 - accuracy: 0.1480 - val_loss: 2.2580 - val_accuracy: 0.1508 - lr: 1.0000e-18\n",
      "Epoch 8/10\n",
      "355/355 [==============================] - 38s 106ms/step - loss: 2.2582 - accuracy: 0.1480 - val_loss: 2.2580 - val_accuracy: 0.1508 - lr: 1.0000e-21\n",
      "Epoch 9/10\n",
      "355/355 [==============================] - 38s 106ms/step - loss: 2.2582 - accuracy: 0.1480 - val_loss: 2.2580 - val_accuracy: 0.1508 - lr: 1.0000e-24\n",
      "Epoch 10/10\n",
      "355/355 [==============================] - 38s 106ms/step - loss: 2.2582 - accuracy: 0.1480 - val_loss: 2.2580 - val_accuracy: 0.1508 - lr: 1.0000e-27\n",
      "Potrzebny czas do wykonania operacji to:  7  minut\n"
     ]
    }
   ],
   "source": [
    "now = datetime.datetime.now()\n",
    "history = model.fit(x_train, y_train, epochs=10, callbacks=[reduceLR],validation_data=(x_valid, y_valid))\n",
    "time = datetime.datetime.now()-now\n",
    "print(\"Potrzebny czas do wykonania operacji to: \",int(time.seconds/60),\" minut\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8a0a30-5d93-4634-9b98-01db77694504",
   "metadata": {},
   "source": [
    "## 7. Zapis architektury\n",
    "Jednak my nie będziemy testować od razu naszego modelu. Do tego celu przygotujemy oddzielny notebook. Dlatego, aby nie utracić naszej pracy, zapiszemy nas wyuczony model do pliku."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5dcada86-9b19-439e-858c-363f987a16fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Models/DNN_full.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ecd7e5-7727-46b6-85a2-372df6cfb4ef",
   "metadata": {},
   "source": [
    "## 8. Zapis otrzymanych wyników podczas nauki\n",
    "Po zakończeniu uczenia zapisujemy wyniki, które otrzymaliśmy podczas uczenie modelu do pliku CSV. Pozwoli nam to później przeanalizować proces uczenia i walidacji i porównać te dane z różnymi modelami."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "189bec63-2e8f-4a9f-8406-a0ebd82d28d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "historyModelLearning = pd.DataFrame()\n",
    "historyModelLearning['loss'] = history.history['loss']\n",
    "historyModelLearning['accuracy'] = history.history['accuracy']\n",
    "historyModelLearning['val_loss'] = history.history['val_loss']\n",
    "historyModelLearning['val_accuracy'] = history.history['val_accuracy']\n",
    "historyModelLearning.to_csv('ResultLearning/DDN_full.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1434d4d4-3602-4f16-bd44-6fcd5755ae07",
   "metadata": {},
   "source": [
    "## 9. Sprawdzenie uzyskanych wyników\n",
    "Celem tego elementu jest wstępne sprawdzenie uzyskanych wyników. Pozwoli to na porównanie wyników z predykcją w zapisanym modelu. Dzięki temu uzyskamy informację czy otrzymane wyniku różnią się od siebie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "959c9ce0-6719-44d7-9ed2-8beeb35a0667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111/111 [==============================] - 1s 11ms/step\n",
      "Otrzymany wynik to:  15.135287485907552  %\n"
     ]
    }
   ],
   "source": [
    "predict = model.predict(x_test).argmax(axis=1)\n",
    "print(\"Otrzymany wynik to: \",(accuracy_score(y_test, predict)*100),\" %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727118f1-405e-4ced-97ca-cc715aa44e0d",
   "metadata": {},
   "source": [
    "## Literatura\n",
    "1. Tenzin Migmar 2021 Galaxy Multi-Image Classification with LeNet-5 (Jupiter NoteBook)\n",
    "2. Paweł Krakowiak, Deep learning w języku Python — Konwolucyjne Sieci Neuronowe\n",
    "3. https://builtin.com/machine-learning/relu-activation-function\n",
    "4. https://datascience.eu/pl/uczenie-maszynowe/relu-funkcja-aktywujaca/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329b5644-be04-4f0d-a1c4-1d6079e1c952",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
