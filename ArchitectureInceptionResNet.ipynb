{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4a65deb-102e-4ad2-92f2-3ff9d340a96b",
   "metadata": {},
   "source": [
    "# Splątane sieci neuronowe CNN – architektura InceptionResNet \n",
    "---\n",
    "autor: mgr inż. Grzegorz Kossakowski"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de60196-61c7-4979-8274-35c7548943c0",
   "metadata": {},
   "source": [
    "## 1. Opis architektury\n",
    "InceptionResNet [1][2] jest to połączenie dwóch sieci Inception oraz ResNet. Spowodowało to znaczne przyspieszenie szkolenia sieci i pozwoliło poprawić wydajność oraz otrzymywane wyniki.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a75435b-d66d-44e6-a2fa-5ecc48e2b38c",
   "metadata": {},
   "source": [
    "## 2. Pobranie potrzebnych bibliotek\n",
    "Kolejnym krokiem jest wczytanie wszystkich potrzebnych bibliotek, dzięki którym będzie możliwe wykorzystanie ich w procesie klasyfikacji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a82fd330-0d74-4c15-8f26-3da61c332ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_ENABLE_ONEDNN_OPTS=0\n",
    "from astropy.io import fits\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "from keras import Sequential\n",
    "from tests.test_layers import Dense, Flatten\n",
    "from keras.applications import InceptionResNetV2\n",
    "from keras.applications.inception_resnet_v2 import preprocess_input \n",
    "import pandas as pd\n",
    "import datetime\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00adab72-d8c2-4a5c-92c7-7f2d54de5cb9",
   "metadata": {},
   "source": [
    "## 3. Pobranie danych z pliku fits\n",
    "Dlatego że wcześniej podzieliliśmy dane na odpowiednie części, teraz pobieramy dwa zbiory. Pierwszy z nich to zbiór, na którym będziemy uczyć nasz model. Drugi to zbiór walidacyjny."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "843b6bd8-8577-4d40-8d3d-bdee4e18c264",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdu_train = fits.open('Data/train.fits')\n",
    "hdu_valid = fits.open('Data/valid.fits')\n",
    "hdu_test = fits.open('Data/test.fits')\n",
    "x_train = hdu_train[0].data\n",
    "y_train = hdu_train[1].data\n",
    "x_valid = hdu_valid[0].data\n",
    "y_valid = hdu_valid[1].data\n",
    "x_test = hdu_test[0].data\n",
    "y_test = hdu_test[1].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9690d858-350e-4064-84f7-911ebab4f971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11350, 256, 256, 3), (2838, 256, 256, 3), (3548, 256, 256, 3), numpy.ndarray)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_valid.shape, x_test.shape, type(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf6a960-35f6-46d1-bb0a-c5a67fa0d668",
   "metadata": {},
   "source": [
    "## 4. Pobranie danych \n",
    "W tym kroku pobieramy dane, a następnie przygotowujemy je do klasyfikacji. Modele głębokiej sieci neuronowej [4] wymaga danych z zakresu 0..1, dlatego wszystkie wartości w danych są dzielone przez 255. Powodem takiego zachowania jest fakt, że dane obrazów są przechowywane w zakresie liczb 0..255. Dzielenie przez 255 powoduje, że dane zostaną zapisane w zakresie od 0..1, zgodnie z wymaganiami modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13190918-6978-4357-9e7c-b92b7c2fd775",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduceLR = ReduceLROnPlateau(monitor='accuracy', factor=.001, patience=1, min_delta=0.01, mode=\"auto\")\n",
    "x_train = preprocess_input(x_train)\n",
    "x_valid = preprocess_input(x_valid)\n",
    "x_test = preprocess_input(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fda4ac-f414-458c-a813-deea7e986887",
   "metadata": {},
   "source": [
    "## 5. Ustawienie sposobu nauki\n",
    "Modele, które używany są już wstępnie wyuczone, dlatego chciałem sprawdzić, jak dany model będzie się zachowywał w dwóch przypadkach. Pierwszy przypadek gdy wartość fullStudy zostanie ustawiona na false wtedy model będzie wykorzystywał wcześniej nauczony model i na ostatnich warstwach będzie douczał tylko danymi astronomicznymi. Gdy ustawimy wartość na true, model od początku będzie, wykonał naukę architektury. Wcześniejsza nauka nie będzie brana pod uwagę. Pozwoli to ocenić, który sposób jest bardziej efektywny."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a16dd7f8-4ab6-4f59-9be0-dd47d38cf084",
   "metadata": {},
   "outputs": [],
   "source": [
    "fullStudy = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd9eb4f-630c-47a8-9581-ae56dfce14dc",
   "metadata": {},
   "source": [
    "## 6. Budowa modelu.\n",
    "Model w tym przypadku jest bardzo prosty. Jest to model warstwowy i jako pierwsza warstwa jest to warstwa flatten. Zadaniem tej warstwy jest spłaszczenie obrazu z wymiarów 69*69 na pojedynczy ciąg, jest to warstwa wejściowa. Kolejną warstwą jest warstwa ukryta z aktywatorem RELU. Aktywator ten powoduje, że każdy otrzymany wynik ujemy, zostaje zamieniony na zero [5][6]. Pozwala to na przełamanie liniowości procesu. Ostatnią warstwą jest gęsto połączona warstwa wyjściowa. W naszym modelu klasyfikacja odbywa się dla 10 kategorii dlatego właśnie taka."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fbf1f63-8a28-4a35-a980-dc3b8b5960c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liczba warstw:  780\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inception_resnet_v2 (Funct  (None, 6, 6, 1536)        54336736  \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 55296)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                552970    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 54889706 (209.39 MB)\n",
      "Trainable params: 42473962 (162.03 MB)\n",
      "Non-trainable params: 12415744 (47.36 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = InceptionResNetV2(weights='imagenet', include_top=False, input_shape=(256, 256,3))\n",
    "numberLayers = len(base_model.layers)\n",
    "numberClosedLayers = int(numberLayers/2)\n",
    "print(\"Liczba warstw: \", numberLayers)\n",
    "if fullStudy == True:\n",
    "    base_model.trainable = True\n",
    "else:\n",
    "    for layer in base_model.layers[:numberClosedLayers]:\n",
    "        layer.trainable = False\n",
    "\n",
    "model_optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer=model_optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7559b8dc-5bd2-4c64-8269-dd11088753ca",
   "metadata": {},
   "source": [
    "## 7. Uczenie\n",
    "W tym momencie model zaczyna proces uczenia. Czyli otrzymuje dwa zbiory danych i etykiet. Pierwszy z nich to dane, na podstawie których model się uczy. Drugi mniejszy zbiór jest zbiorem walidacyjnym, który pozwala na sprawdzenie postępów w nauce, na danych, których model jeszcze nie widział. Pozwala to ocenić postępy w nauce już w czasie uczenia. Kolejny zbiór danych zostanie wykorzystany na końcu celem ostatecznego sprawdzenia poprawności działania modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cd86063-8618-4297-bfbd-04b43cdbab62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "355/355 [==============================] - 1018s 3s/step - loss: 1.4058 - accuracy: 0.6239 - val_loss: 913.9076 - val_accuracy: 0.4908 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "355/355 [==============================] - 1008s 3s/step - loss: 0.7604 - accuracy: 0.7574 - val_loss: 17989.4688 - val_accuracy: 0.1452 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "355/355 [==============================] - 999s 3s/step - loss: 0.6315 - accuracy: 0.7960 - val_loss: 0.7108 - val_accuracy: 0.7914 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "355/355 [==============================] - 998s 3s/step - loss: 0.4908 - accuracy: 0.8413 - val_loss: 8193.0547 - val_accuracy: 0.2304 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "355/355 [==============================] - 995s 3s/step - loss: 0.4113 - accuracy: 0.8619 - val_loss: 0.7153 - val_accuracy: 0.7724 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "355/355 [==============================] - 996s 3s/step - loss: 0.3755 - accuracy: 0.8878 - val_loss: 40.3876 - val_accuracy: 0.6223 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "355/355 [==============================] - 996s 3s/step - loss: 1.3155 - accuracy: 0.8107 - val_loss: 0.7085 - val_accuracy: 0.7607 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "355/355 [==============================] - 996s 3s/step - loss: 1.0177 - accuracy: 0.8421 - val_loss: 2.7444 - val_accuracy: 0.8006 - lr: 1.0000e-06\n",
      "Epoch 9/10\n",
      "355/355 [==============================] - 996s 3s/step - loss: 0.7921 - accuracy: 0.8537 - val_loss: 3.4327 - val_accuracy: 0.7960 - lr: 1.0000e-09\n",
      "Epoch 10/10\n",
      "355/355 [==============================] - 998s 3s/step - loss: 0.8569 - accuracy: 0.8514 - val_loss: 2.8916 - val_accuracy: 0.7999 - lr: 1.0000e-12\n",
      "Potrzebny czas do wykonania operacji to:  166  minut\n"
     ]
    }
   ],
   "source": [
    "now = datetime.datetime.now()\n",
    "history = model.fit(x_train, y_train, epochs=10, callbacks=[reduceLR],validation_data=(x_valid, y_valid))\n",
    "time = datetime.datetime.now()-now\n",
    "print(\"Potrzebny czas do wykonania operacji to: \",int(time.seconds/60),\" minut\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10682377-5fd3-41bb-86cf-ecd5122023ca",
   "metadata": {},
   "source": [
    "## 8. Zapis architektury"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08dcdc15-eaf9-4d43-8ba3-07f7622d96d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if fullStudy == True:\n",
    "    model.save('Models/InceptionResNet_full.keras')\n",
    "else:\n",
    "    model.save('Models/InceptionResNet.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c425c8-409e-4d8f-ab45-4b2d14e94899",
   "metadata": {},
   "source": [
    "## 9. Zapis otrzymanych danych podczas nauki\n",
    "Po zakończeniu uczenia zapisujemy dane, które otrzymaliśmy podczas uczenie do pliku CSV. Pozwoli nam to później przeanalizować dane w późniejszym czasie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94aa1164-7182-4eda-a612-62f9c3fcac6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "historyModelLearning = pd.DataFrame()\n",
    "historyModelLearning['loss'] = history.history['loss']\n",
    "historyModelLearning['accuracy'] = history.history['accuracy']\n",
    "historyModelLearning['val_loss'] = history.history['val_loss']\n",
    "historyModelLearning['val_accuracy'] = history.history['val_accuracy']\n",
    "if fullStudy == True:\n",
    "    historyModelLearning.to_csv('ResultsLearning/InceptionRestNet_full.csv', index=True)\n",
    "else:\n",
    "    historyModelLearning.to_csv('ResultsLearning/InceptionRestNet.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5dfe477-03de-4c0d-a728-b12c0a55bb08",
   "metadata": {},
   "source": [
    "## 10. Sprawdzenie uzyskanych wyników\n",
    "Celem tego elementu jest wstępne sprawdzenie uzyskanych wyników. Pozwoli to na porównanie wyników z predykcją w zapisanym modelu. Dzięki temu uzyskamy informację czy otrzymane wyniku różnią się od siebie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8fbcbb1-5d62-4f93-8fde-bdbf5c7acd23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111/111 [==============================] - 144s 1s/step\n",
      "Otrzymany wynik to:  79.8196166854566  %\n"
     ]
    }
   ],
   "source": [
    "predict = model.predict(x_test).argmax(axis=1)\n",
    "print(\"Otrzymany wynik to: \",(accuracy_score(y_test, predict)*100),\" %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e63262-e19c-48a1-a8a9-a471fe379205",
   "metadata": {},
   "source": [
    "## Literatura\n",
    "1. https://arxiv.org/abs/1602.07261 dostęp 11.10.2024\n",
    "2. https://keras.io/2.17/api/applications/inceptionresnetv2/ dostęp 11.10.2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b6d647-b5be-4221-9044-81643f9b6e1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
