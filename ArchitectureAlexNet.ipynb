{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4a65deb-102e-4ad2-92f2-3ff9d340a96b",
   "metadata": {},
   "source": [
    "# Splątane sieci neuronowe CNN – architektura AlexNet \n",
    "---\n",
    "autor: mgr inż. Grzegorz Kossakowski"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de60196-61c7-4979-8274-35c7548943c0",
   "metadata": {},
   "source": [
    "## 1. Opis architektury\n",
    "AlexNet [1][2] jest architekturą splątanych sieci neuronowych CNN. Została stworzona przez Alex Kizhevsky i Ilya Sutskever. W pracach uczestniczył również Geoffrey Hinton, który był promotorem doktoratu as Krizhevsky. Jest bardziej rozbudowany niż LeNet5. Głównym celem było uczestnictwo w zawodach ImageNet Large Scale Visual Recognition Challenge (ILSVRC), które wygrał w 2012 roku."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a75435b-d66d-44e6-a2fa-5ecc48e2b38c",
   "metadata": {},
   "source": [
    "## 2. Pobranie potrzebnych bibliotek\n",
    "Kolejnym krokiem jest wczytanie wszystkich potrzebnych bibliotek, dzięki którym będzie możliwe wykorzystanie ich w procesie klasyfikacji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a82fd330-0d74-4c15-8f26-3da61c332ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_ENABLE_ONEDNN_OPTS=0\n",
    "from astropy.io import fits\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "from keras import Sequential\n",
    "from tests.test_layers import Dense, Flatten\n",
    "from keras.layers import Conv2D, Dropout, Flatten, Dense, MaxPool2D, BatchNormalization\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00adab72-d8c2-4a5c-92c7-7f2d54de5cb9",
   "metadata": {},
   "source": [
    "## 3. Pobranie danych z pliku fits\n",
    "Dlatego, że wcześniej podzieliliśmy dane na odpowiednie części, teraz pobieramy dwa zbiory. Pierwszy z nich to zbiór uczący, na którym będziemy uczyć nasz model. Drugi to zbiór walidacyjny."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "843b6bd8-8577-4d40-8d3d-bdee4e18c264",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdu_train = fits.open('Data/train.fits')\n",
    "hdu_valid = fits.open('Data/valid.fits')\n",
    "hdu_test = fits.open('Data/test.fits')\n",
    "x_train = hdu_train[0].data\n",
    "y_train = hdu_train[1].data\n",
    "x_valid = hdu_valid[0].data\n",
    "y_valid = hdu_valid[1].data\n",
    "x_test = hdu_test[0].data\n",
    "y_test = hdu_test[1].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9690d858-350e-4064-84f7-911ebab4f971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11350, 256, 256, 3), (2838, 256, 256, 3), (3548, 256, 256, 3), numpy.ndarray)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_valid.shape, x_test.shape, type(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf6a960-35f6-46d1-bb0a-c5a67fa0d668",
   "metadata": {},
   "source": [
    "## 4. Pobranie danych \n",
    "W tym kroku pobieramy dane, a następnie przygotowujemy je do klasyfikacji. Modele głębokiej sieci neuronowej [4] wymaga danych z zakresu 0..1, dlatego wszystkie wartości w danych są dzielone przez 255. Powodem takiego zachowania jest fakt, że dane obrazów są przechowywane w zakresie liczb 0..255. Dzielenie przez 255 powoduje, że dane zostaną zapisane w zakresie od 0..1, zgodnie z wymaganiami modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13190918-6978-4357-9e7c-b92b7c2fd775",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduceLR = ReduceLROnPlateau(monitor='accuracy', factor=.001, patience=1, min_delta=0.01, mode=\"auto\")\n",
    "x_train = x_train / 255.0\n",
    "x_valid = x_valid / 255.0\n",
    "x_test = x_test/ 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd9eb4f-630c-47a8-9581-ae56dfce14dc",
   "metadata": {},
   "source": [
    "## 5. Budowa modelu.\n",
    "Model można podzielić na dwie podstawowe części. Pierwsza część to warstwy splątane. Naprzemiennie są układane warstwy Conv2D, BatchNormalization oraz MaxPool2D. Kolejność ułożenia warstw jest zgodna z AlexNet. Kolejne warstwy zaczynające się od warstwy flatten są zwykłym modelem głębokiego uczenia. Zadaniem warstwy flaten jest spłaszczenie obrazu z wymiarów 256*256 na pojedynczy ciąg. Kolejną warstwą jest warstwa ukryta z aktywatorem RELU. Aktywator ten powoduje, że każdy otrzymany wynik ujemy, zostaje zamieniony na zero [3][4]. Pozwala to na przełamanie liniowości procesu. Ostatnią warstwą jest gęsto połączona warstwa wyjściowa. W naszym modelu klasyfikacja odbywa się dla 10 kategorii, dlatego właśnie taka wartość jest wybrana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fbf1f63-8a28-4a35-a980-dc3b8b5960c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 62, 62, 96)        34944     \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 62, 62, 96)        384       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 30, 30, 96)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 30, 30, 256)       614656    \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 30, 30, 256)       1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 14, 14, 256)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 14, 14, 384)       885120    \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 14, 14, 384)       1536      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 14, 14, 384)       1327488   \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 14, 14, 384)       1536      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 14, 14, 256)       884992    \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 14, 14, 256)       1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 6, 6, 256)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 9216)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              37752832  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                40970     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 41546506 (158.49 MB)\n",
      "Trainable params: 41543754 (158.48 MB)\n",
      "Non-trainable params: 2752 (10.75 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters=96, kernel_size=(11, 11), strides=(4, 4), activation=\"relu\", input_shape=(256, 256, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(3, 3), strides= (2, 2)))\n",
    "model.add(Conv2D(filters=256, kernel_size=(5, 5), strides=(1, 1), activation=\"relu\", padding=\"same\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "model.add(Conv2D(filters=384, kernel_size=(3, 3), strides=(1, 1), activation=\"relu\", padding=\"same\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=384, kernel_size=(3, 3), strides=(1, 1), activation=\"relu\", padding=\"same\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 1), activation=\"relu\", padding=\"same\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "model_optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=model_optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7559b8dc-5bd2-4c64-8269-dd11088753ca",
   "metadata": {},
   "source": [
    "## 6. Uczenie\n",
    "W tym momencie model zaczyna proces uczenia. Czyli otrzymuje dwa zbiory danych i etykiet. Pierwszy z nich to dane, na podstawie których model się uczy. Drugi mniejszy zbiór jest zbiorem walidacyjnym, który pozwala na sprawdzenie postępów w nauce, na danych, których model jeszcze nie widział. Pozwala to ocenić postępy w nauce już w czasie uczenia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cd86063-8618-4297-bfbd-04b43cdbab62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "355/355 [==============================] - 255s 711ms/step - loss: 5.4553 - accuracy: 0.2071 - val_loss: 2.5066 - val_accuracy: 0.1920 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "355/355 [==============================] - 247s 696ms/step - loss: 2.0252 - accuracy: 0.2663 - val_loss: 1.9046 - val_accuracy: 0.2999 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "355/355 [==============================] - 245s 691ms/step - loss: 1.8727 - accuracy: 0.3031 - val_loss: 1.7225 - val_accuracy: 0.3386 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "355/355 [==============================] - 244s 688ms/step - loss: 1.7589 - accuracy: 0.3395 - val_loss: 1.5415 - val_accuracy: 0.4091 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "355/355 [==============================] - 243s 686ms/step - loss: 1.7524 - accuracy: 0.3441 - val_loss: 1.7676 - val_accuracy: 0.3520 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "355/355 [==============================] - 241s 679ms/step - loss: 1.6696 - accuracy: 0.3543 - val_loss: 1.5769 - val_accuracy: 0.3999 - lr: 1.0000e-06\n",
      "Epoch 7/10\n",
      "355/355 [==============================] - 242s 681ms/step - loss: 1.6730 - accuracy: 0.3514 - val_loss: 1.5646 - val_accuracy: 0.4006 - lr: 1.0000e-06\n",
      "Epoch 8/10\n",
      "355/355 [==============================] - 244s 686ms/step - loss: 1.6559 - accuracy: 0.3582 - val_loss: 1.5639 - val_accuracy: 0.4003 - lr: 1.0000e-09\n",
      "Epoch 9/10\n",
      "355/355 [==============================] - 242s 682ms/step - loss: 1.6518 - accuracy: 0.3574 - val_loss: 1.5644 - val_accuracy: 0.4006 - lr: 1.0000e-12\n",
      "Epoch 10/10\n",
      "355/355 [==============================] - 240s 676ms/step - loss: 1.6544 - accuracy: 0.3667 - val_loss: 1.5645 - val_accuracy: 0.4006 - lr: 1.0000e-15\n",
      "Potrzebny czas do wykonania operacji to:  41  minut\n"
     ]
    }
   ],
   "source": [
    "now = datetime.datetime.now()\n",
    "history = model.fit(x_train, y_train, epochs=10, callbacks=[reduceLR],validation_data=(x_valid, y_valid))\n",
    "time = datetime.datetime.now()-now\n",
    "print(\"Potrzebny czas do wykonania operacji to: \",int(time.seconds/60),\" minut\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10682377-5fd3-41bb-86cf-ecd5122023ca",
   "metadata": {},
   "source": [
    "## 7. Zapis architektury\n",
    "Jednak my nie będziemy testować od razu naszego modelu. Do tego celu przygotujemy oddzielny notebook. Dlatego, aby nie utracić naszej pracy, zapiszemy nas wyuczony model do pliku."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08dcdc15-eaf9-4d43-8ba3-07f7622d96d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Models/AlexNet_full.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c425c8-409e-4d8f-ab45-4b2d14e94899",
   "metadata": {},
   "source": [
    "## 8. Zapis otrzymanych danych podczas nauki\n",
    "Po zakończeniu uczenia zapisujemy dane, które otrzymaliśmy podczas uczenie do pliku CSV. Pozwoli nam to później przeanalizować proces uczenia i walidacji i porównać te dane z różnymi modelami."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94aa1164-7182-4eda-a612-62f9c3fcac6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "historyModelLearning = pd.DataFrame()\n",
    "historyModelLearning['loss'] = history.history['loss']\n",
    "historyModelLearning['accuracy'] = history.history['accuracy']\n",
    "historyModelLearning['val_loss'] = history.history['val_loss']\n",
    "historyModelLearning['val_accuracy'] = history.history['val_accuracy']\n",
    "historyModelLearning.to_csv('ResultLearning/AlexNet_full.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef438614-3d1a-4d74-bfda-05eb43f2bc0e",
   "metadata": {},
   "source": [
    "## 9. Sprawdzenie uzyskanych wyników\n",
    "Celem tego elementu jest wstępne sprawdzenie uzyskanych wyników. Pozwoli to na porównanie wyników z predykcją w zapisanym modelu. Dzięki temu uzyskamy informację czy otrzymane wyniku różnią się od siebie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38400b11-b2ea-4071-92c3-7e5e821309fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111/111 [==============================] - 20s 177ms/step\n",
      "Otrzymany wynik to:  42.13641488162345  %\n"
     ]
    }
   ],
   "source": [
    "predict = model.predict(x_test).argmax(axis=1)\n",
    "print(\"Otrzymany wynik to: \",(accuracy_score(y_test, predict)*100),\" %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e63262-e19c-48a1-a8a9-a471fe379205",
   "metadata": {},
   "source": [
    "## Literatura\n",
    "1. https://medium.com/@siddheshb008/alexnet-architecture-explained-b6240c528bd5 dostęp 4.10.2024\n",
    "2. Bartosz Michalski, Małgorzata Plechawska-Wójcik, Porównanie modeli LeNet-5, AlexNet i GoogLeNet w rozpoznawaniu pisma ręcznego, 2022\n",
    "3. https://builtin.com/machine-learning/relu-activation-function\n",
    "4. https://datascience.eu/pl/uczenie-maszynowe/relu-funkcja-aktywujaca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b6d647-b5be-4221-9044-81643f9b6e1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
