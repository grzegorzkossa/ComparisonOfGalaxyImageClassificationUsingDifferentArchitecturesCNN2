{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4a65deb-102e-4ad2-92f2-3ff9d340a96b",
   "metadata": {},
   "source": [
    "# Splątane sieci neuronowe CNN – architektura AlexNet \n",
    "---\n",
    "autor: mgr inż. Grzegorz Kossakowski"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de60196-61c7-4979-8274-35c7548943c0",
   "metadata": {},
   "source": [
    "## 1. Opis architektury\n",
    "AlexNet [1][2] jest architekturą splątanych sieci neuronowych CNN. Została stworzona przez Alex Kizhevsky i Ilya Sutskever. W pracach uczestniczył również Geoffrey Hinton, który był promotorem doktoratu as Krizhevsky. Jest bardziej rozbudowany niż LeNet5. Głównym celem było uczestnictwo w zawodach ImageNet Large Scale Visual Recognition Challenge (ILSVRC), które wygrał w 2012 roku."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a75435b-d66d-44e6-a2fa-5ecc48e2b38c",
   "metadata": {},
   "source": [
    "## 2. Pobranie potrzebnych bibliotek\n",
    "Kolejnym krokiem jest wczytanie wszystkich potrzebnych bibliotek, dzięki którym będzie możliwe wykorzystanie ich w procesie klasyfikacji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a82fd330-0d74-4c15-8f26-3da61c332ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_ENABLE_ONEDNN_OPTS=0\n",
    "from astropy.io import fits\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "from keras import Sequential\n",
    "from tests.test_layers import Dense, Flatten\n",
    "from keras.layers import Conv2D, Dropout, Flatten, Dense, MaxPool2D, BatchNormalization\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00adab72-d8c2-4a5c-92c7-7f2d54de5cb9",
   "metadata": {},
   "source": [
    "## 3. Pobranie danych z pliku fits\n",
    "Dlatego, że wcześniej podzieliliśmy dane na odpowiednie części, teraz pobieramy dwa zbiory. Pierwszy z nich to zbiór uczący, na którym będziemy uczyć nasz model. Drugi to zbiór walidacyjny."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "843b6bd8-8577-4d40-8d3d-bdee4e18c264",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdu_train = fits.open('Data/train.fits')\n",
    "hdu_valid = fits.open('Data/valid.fits')\n",
    "x_train = hdu_train[0].data\n",
    "y_train = hdu_train[1].data\n",
    "x_valid = hdu_valid[0].data\n",
    "y_valid = hdu_valid[1].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9690d858-350e-4064-84f7-911ebab4f971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11350, 256, 256, 3), (2838, 256, 256, 3), numpy.ndarray)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_valid.shape, type(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf6a960-35f6-46d1-bb0a-c5a67fa0d668",
   "metadata": {},
   "source": [
    "## 4. Pobranie danych \n",
    "W tym kroku pobieramy dane, a następnie przygotowujemy je do klasyfikacji. Modele głębokiej sieci neuronowej [4] wymaga danych z zakresu 0..1, dlatego wszystkie wartości w danych są dzielone przez 255. Powodem takiego zachowania jest fakt, że dane obrazów są przechowywane w zakresie liczb 0..255. Dzielenie przez 255 powoduje, że dane zostaną zapisane w zakresie od 0..1, zgodnie z wymaganiami modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13190918-6978-4357-9e7c-b92b7c2fd775",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduceLR = ReduceLROnPlateau(monitor='accuracy', factor=.001, patience=1, min_delta=0.01, mode=\"auto\")\n",
    "x_train = x_train / 255.0\n",
    "x_valid = x_valid / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd9eb4f-630c-47a8-9581-ae56dfce14dc",
   "metadata": {},
   "source": [
    "## 5. Budowa modelu.\n",
    "Model można podzielić na dwie podstawowe części. Pierwsza część to warstwy splątane. Naprzemiennie są układane warstwy Conv2D, BatchNormalization oraz MaxPool2D. Kolejność ułożenia warstw jest zgodna z AlexNet. Kolejne warstwy zaczynające się od warstwy flatten są zwykłym modelem głębokiego uczenia. Zadaniem warstwy flaten jest spłaszczenie obrazu z wymiarów 256*256 na pojedynczy ciąg. Kolejną warstwą jest warstwa ukryta z aktywatorem RELU. Aktywator ten powoduje, że każdy otrzymany wynik ujemy, zostaje zamieniony na zero [3][4]. Pozwala to na przełamanie liniowości procesu. Ostatnią warstwą jest gęsto połączona warstwa wyjściowa. W naszym modelu klasyfikacja odbywa się dla 10 kategorii, dlatego właśnie taka wartość jest wybrana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fbf1f63-8a28-4a35-a980-dc3b8b5960c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 62, 62, 96)        34944     \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 62, 62, 96)        384       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 30, 30, 96)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 30, 30, 256)       614656    \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 30, 30, 256)       1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 14, 14, 256)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 14, 14, 384)       885120    \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 14, 14, 384)       1536      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 14, 14, 384)       1327488   \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 14, 14, 384)       1536      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 14, 14, 256)       884992    \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 14, 14, 256)       1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 6, 6, 256)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 9216)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              37752832  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                40970     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 41546506 (158.49 MB)\n",
      "Trainable params: 41543754 (158.48 MB)\n",
      "Non-trainable params: 2752 (10.75 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters=96, kernel_size=(11, 11), strides=(4, 4), activation=\"relu\", input_shape=(256, 256, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(3, 3), strides= (2, 2)))\n",
    "model.add(Conv2D(filters=256, kernel_size=(5, 5), strides=(1, 1), activation=\"relu\", padding=\"same\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "model.add(Conv2D(filters=384, kernel_size=(3, 3), strides=(1, 1), activation=\"relu\", padding=\"same\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=384, kernel_size=(3, 3), strides=(1, 1), activation=\"relu\", padding=\"same\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 1), activation=\"relu\", padding=\"same\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "model_optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=model_optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7559b8dc-5bd2-4c64-8269-dd11088753ca",
   "metadata": {},
   "source": [
    "## 6. Uczenie\n",
    "W tym momencie model zaczyna proces uczenia. Czyli otrzymuje dwa zbiory danych i etykiet. Pierwszy z nich to dane, na podstawie których model się uczy. Drugi mniejszy zbiór jest zbiorem walidacyjnym, który pozwala na sprawdzenie postępów w nauce, na danych, których model jeszcze nie widział. Pozwala to ocenić postępy w nauce już w czasie uczenia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cd86063-8618-4297-bfbd-04b43cdbab62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "355/355 [==============================] - 251s 700ms/step - loss: 6.3898 - accuracy: 0.2207 - val_loss: 3.6178 - val_accuracy: 0.1515 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "355/355 [==============================] - 242s 681ms/step - loss: 1.8181 - accuracy: 0.3204 - val_loss: 1.7775 - val_accuracy: 0.3277 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "355/355 [==============================] - 241s 678ms/step - loss: 1.6687 - accuracy: 0.3731 - val_loss: 11.2617 - val_accuracy: 0.1589 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "355/355 [==============================] - 240s 676ms/step - loss: 1.6024 - accuracy: 0.3981 - val_loss: 2.1563 - val_accuracy: 0.2579 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "355/355 [==============================] - 240s 675ms/step - loss: 1.5221 - accuracy: 0.4335 - val_loss: 1.6190 - val_accuracy: 0.4235 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "355/355 [==============================] - 240s 676ms/step - loss: 1.4773 - accuracy: 0.4545 - val_loss: 2.1031 - val_accuracy: 0.3612 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "355/355 [==============================] - 239s 674ms/step - loss: 1.4113 - accuracy: 0.4856 - val_loss: 3.2347 - val_accuracy: 0.3555 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "355/355 [==============================] - 240s 676ms/step - loss: 1.3597 - accuracy: 0.5035 - val_loss: 1.2892 - val_accuracy: 0.5444 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "355/355 [==============================] - 238s 672ms/step - loss: 1.2944 - accuracy: 0.5326 - val_loss: 1.3105 - val_accuracy: 0.5627 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "355/355 [==============================] - 240s 676ms/step - loss: 1.4049 - accuracy: 0.4947 - val_loss: 1.4003 - val_accuracy: 0.4912 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=10, callbacks=[reduceLR],validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10682377-5fd3-41bb-86cf-ecd5122023ca",
   "metadata": {},
   "source": [
    "## 7. Zapis architektury\n",
    "Jednak my nie będziemy testować od razu naszego modelu. Do tego celu przygotujemy oddzielny notebook. Dlatego, aby nie utracić naszej pracy, zapiszemy nas wyuczony model do pliku."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08dcdc15-eaf9-4d43-8ba3-07f7622d96d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Models/AlexNet_full.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c425c8-409e-4d8f-ab45-4b2d14e94899",
   "metadata": {},
   "source": [
    "## 8. Zapis otrzymanych danych podczas nauki\n",
    "Po zakończeniu uczenia zapisujemy dane, które otrzymaliśmy podczas uczenie do pliku CSV. Pozwoli nam to później przeanalizować proces uczenia i walidacji i porównać te dane z różnymi modelami."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94aa1164-7182-4eda-a612-62f9c3fcac6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "historyModelLearning = pd.DataFrame()\n",
    "historyModelLearning['loss'] = history.history['loss']\n",
    "historyModelLearning['accuracy'] = history.history['accuracy']\n",
    "historyModelLearning['val_loss'] = history.history['val_loss']\n",
    "historyModelLearning['val_accuracy'] = history.history['val_accuracy']\n",
    "historyModelLearning.to_csv('ResultLearning/AlexNet_full.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e63262-e19c-48a1-a8a9-a471fe379205",
   "metadata": {},
   "source": [
    "## Literatura\n",
    "1. https://medium.com/@siddheshb008/alexnet-architecture-explained-b6240c528bd5 dostęp 4.10.2024\n",
    "2. Bartosz Michalski, Małgorzata Plechawska-Wójcik, Porównanie modeli LeNet-5, AlexNet i GoogLeNet w rozpoznawaniu pisma ręcznego, 2022\n",
    "3. https://builtin.com/machine-learning/relu-activation-function\n",
    "4. https://datascience.eu/pl/uczenie-maszynowe/relu-funkcja-aktywujaca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b6d647-b5be-4221-9044-81643f9b6e1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
